{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "base_dir = \"datalab/6210\"\n",
    "path_training = os.path.join(base_dir, \"sample_training.h5\", \"sample_training.h5\")\n",
    "path_test = os.path.join(base_dir, \"sample_test.h5\", \"sample_test.h5\")\n",
    "\n",
    "fid_training = h5py.File(path_training,'r')\n",
    "fid_validation = h5py.File(path_test,'r')\n",
    "\n",
    "print(\"shape for each channel.\")\n",
    "s1_training = fid_training['sen1']\n",
    "print(s1_training.shape)\n",
    "s2_training = fid_training['sen2']\n",
    "print(s2_training.shape)\n",
    "label_training = fid_training['label']\n",
    "print(label_training.shape)\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(\"validation part\")\n",
    "s1_validation = fid_validation['sen1']\n",
    "print(s1_validation.shape)\n",
    "s2_validation = fid_validation['sen2']\n",
    "print(s2_validation.shape)\n",
    "label_validation = fid_validation['label']\n",
    "print(label_validation.shape)\n",
    "\n",
    "print(\"show class distribution\")\n",
    "label_qty = np.sum(fid_training[\"label\"], axis=0)\n",
    "print(label_qty)\n",
    "plt.plot(label_qty)\n",
    "plt.title(\"class distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization, plot the first pair of Sentinel-1 and Sentinel-2 patches of training.h5\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(10*np.log10(s1_training[0,:,:,4]),cmap=plt.cm.get_cmap('gray'));\n",
    "plt.colorbar()\n",
    "plt.title('Sentinel-1')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(s2_training[0,:,:,1],cmap=plt.cm.get_cmap('gray'));\n",
    "plt.colorbar()\n",
    "plt.title('Sentinel-2')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "### as you can see, it is difficult to identify the image as a class by human."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "## for a small dataset train and test\n",
    "\n",
    "train_s1 = np.array(fid_training['sen1'])\n",
    "train_s2 = np.array(fid_training['sen2'])\n",
    "train_label = np.array(fid_training['label'])\n",
    "train_y = np.argmax(train_label, axis=1)\n",
    "\n",
    "\n",
    "validation_s1 = np.array(fid_validation['sen1'])\n",
    "validation_s2 = np.array(fid_validation['sen2'])\n",
    "validation_label = np.array(fid_validation['label'])\n",
    "validation_y = np.argmax(validation_label, axis=1)\n",
    "\n",
    "\n",
    "n = train_s1.shape[0]\n",
    "train_s1 = train_s1.reshape((n, -1))\n",
    "train_s2 = train_s2.reshape((n, -1))\n",
    "train_X = np.hstack([train_s1, train_s2])\n",
    "\n",
    "n = validation_s1.shape[0]\n",
    "validation_s1 = validation_s1.reshape((n, -1))\n",
    "validation_s2 = validation_s2.reshape((n, -1))\n",
    "validation_X = np.hstack([validation_s1, validation_s2])\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(train_X, train_y)\n",
    "pre_val_y = clf.predict(validation_X)\n",
    "\n",
    "print(classification_report(validation_y, pre_val_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### simple classification example\n",
    "### Training part using batch\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "train_s1 = s1_training\n",
    "train_s2 = s2_training\n",
    "train_label = label_training\n",
    "clf = SGDClassifier()\n",
    "\n",
    "train_y = np.argmax(train_label, axis=1)\n",
    "classes = list(set(train_y))\n",
    "batch_size = 100\n",
    "n_sampels = train_s1.shape[0]\n",
    "\n",
    "for i in range(0, n_sampels, batch_size):\n",
    "    ## this is an idea for batch training\n",
    "    ## you can relpace this loop for deep learning methods\n",
    "    if i % batch_size * 10 == 0:\n",
    "        print(\"done %d/%d\" % (i, n_sampels))\n",
    "    start_pos = i\n",
    "    end_pos = min(i + batch_size, n_sampels)\n",
    "    train_s1_batch = np.asarray(train_s1[start_pos:end_pos, :, :, :])\n",
    "    train_s2_batch = np.asarray(train_s2[start_pos:end_pos, :, :, :])\n",
    "    cur_batch_size = train_s2_batch.shape[0]\n",
    "    train_s1_batch = train_s1_batch.reshape((cur_batch_size, -1))\n",
    "    train_s2_batch = train_s2_batch.reshape((cur_batch_size, -1))\n",
    "    train_X_batch = np.hstack([train_s1_batch, train_s2_batch])\n",
    "    label_batch = train_y[start_pos:end_pos]\n",
    "    clf.partial_fit(train_X_batch, label_batch, classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make a prediction on validation\n",
    "pred_y = []\n",
    "train_val_y = np.argmax(label_validation, axis=1)\n",
    "batch_size = 100\n",
    "n_val_samples = s2_validation.shape[0]\n",
    "for i in range(0, n_val_samples, batch_size):\n",
    "    start_pos = i\n",
    "    end_pos = min(i + batch_size, n_val_samples)\n",
    "    val_s1_batch = np.asarray(s1_validation[start_pos:end_pos, :, :, :])\n",
    "    val_s2_batch = np.asarray(s2_validation[start_pos:end_pos, :, :, :])\n",
    "    cur_batch_size = val_s2_batch.shape[0]\n",
    "    val_s1_batch = val_s1_batch.reshape((cur_batch_size, -1))\n",
    "    val_s2_batch = val_s2_batch.reshape((cur_batch_size, -1))\n",
    "    val_X_batch = np.hstack([val_s1_batch, val_s2_batch])\n",
    "    tmp_pred_y = clf.predict(val_X_batch)\n",
    "    pred_y.append(tmp_pred_y)\n",
    "pred_y = np.hstack(pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(train_val_y, pred_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
